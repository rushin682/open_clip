{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import html\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "from functools import lru_cache, partial\n",
    "from typing import Callable, Optional, List, Union, Literal\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import ftfy\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import torch\n",
    "\n",
    "\n",
    "GENE_MEDIAN_FILE = Path('/home/ubuntu/Geneformer/geneformer') / \"gene_median_dictionary.pkl\"\n",
    "TOKEN_DICTIONARY_FILE = Path('/home/ubuntu/Geneformer/geneformer') / \"token_dictionary.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_genes(gene_vector, gene_tokens):\n",
    "    \"\"\"\n",
    "    Rank gene expression vector.\n",
    "    \"\"\"\n",
    "    # sort by median-scaled gene values\n",
    "    sorted_indices = np.argsort(-gene_vector)\n",
    "    return gene_tokens[sorted_indices]\n",
    "\n",
    "def tokenize_cell(gene_vector, gene_tokens):\n",
    "    \"\"\"\n",
    "    Convert normalized gene expression vector to tokenized rank value encoding.\n",
    "    \"\"\"\n",
    "    # create array of gene vector with token indices\n",
    "    # mask undetected genes\n",
    "    nonzero_mask = np.nonzero(gene_vector)[0]\n",
    "    # rank by median-scaled gene values\n",
    "    return rank_genes(gene_vector[nonzero_mask], gene_tokens[nonzero_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneformerTokenizer(object):\n",
    "    def __init__(self, \n",
    "                 nproc=1,\n",
    "                 gene_median_file=GENE_MEDIAN_FILE,\n",
    "                 token_dictionary_file=TOKEN_DICTIONARY_FILE\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "            Initialize tokenizer.\n",
    "            Parameters\n",
    "            ----------\n",
    "            custom_attr_name_dict : None, dict\n",
    "                Dictionary of custom attributes to be added to the dataset.\n",
    "                Keys are the names of the attributes in the loom file.\n",
    "                Values are the names of the attributes in the dataset.\n",
    "            nproc : int\n",
    "                Number of processes to use for dataset mapping.\n",
    "            gene_median_file : Path\n",
    "                Path to pickle file containing dictionary of non-zero median\n",
    "                gene expression values across Genecorpus-30M.\n",
    "            token_dictionary_file : Path\n",
    "                Path to pickle file containing token dictionary (Ensembl IDs:token).\n",
    "        \"\"\"\n",
    "\n",
    "        # number of processes for dataset mapping\n",
    "        self.nproc = nproc\n",
    "\n",
    "        # load dictionary of gene normalization factors\n",
    "        # (non-zero median value of expression across Genecorpus-30M)\n",
    "        with open(gene_median_file, \"rb\") as f:\n",
    "            self.gene_median_dict = pickle.load(f)\n",
    "\n",
    "        # load token dictionary (Ensembl IDs:token)\n",
    "        with open(token_dictionary_file, \"rb\") as f:\n",
    "            self.gene_token_dict = pickle.load(f)\n",
    "\n",
    "        # gene keys for full vocabulary\n",
    "        self.gene_keys = list(self.gene_median_dict.keys())\n",
    "\n",
    "        # protein-coding and miRNA gene list dictionary for selecting .loom rows for tokenization\n",
    "        self.genelist_dict = dict(zip(self.gene_keys, [True] * len(self.gene_keys)))\n",
    "    \n",
    "    def tokenize_anndata(self, gexp, target_sum=10_000, chunk_size=512):\n",
    "        \n",
    "        expression = gexp.X.todense() # If needed, convert to dense matrix. Try to avoid this\n",
    "\n",
    "        coding_miRNA_loc = np.where(\n",
    "            [self.genelist_dict.get(i, False) for i in gexp.var[\"ensembl_id\"]]\n",
    "        )[0]\n",
    "        norm_factor_vector = np.array(\n",
    "            [\n",
    "                self.gene_median_dict[i]\n",
    "                for i in gexp.var[\"ensembl_id\"][coding_miRNA_loc]\n",
    "            ]\n",
    "        )\n",
    "        coding_miRNA_ids = gexp.var[\"ensembl_id\"][coding_miRNA_loc]\n",
    "        coding_miRNA_tokens = np.array(\n",
    "            [self.gene_token_dict[i] for i in coding_miRNA_ids]\n",
    "        )\n",
    "\n",
    "        filter_pass_loc = np.array([i for i in range(gexp.shape[0])])\n",
    "\n",
    "        tokenized_cells = []\n",
    "\n",
    "        for i in range(0, len(filter_pass_loc), chunk_size):\n",
    "            idx = filter_pass_loc[i:i+chunk_size]\n",
    "\n",
    "            n_counts = gexp[idx].obs['n_counts'].values[:, None]\n",
    "            X_view = gexp[idx, coding_miRNA_loc].X\n",
    "            X_norm = (X_view / n_counts * target_sum / norm_factor_vector)\n",
    "            X_norm = sp.csr_matrix(X_norm)\n",
    "\n",
    "            tokenized_cells += [\n",
    "                rank_genes(X_norm[i].data, coding_miRNA_tokens[X_norm[i].indices])\n",
    "                for i in range(X_norm.shape[0])\n",
    "            ]\n",
    "\n",
    "        gexp.obsm['geneformer_emb'] = np.array(tokenized_cells)\n",
    "\n",
    "        # save anndata object to datasets/dataset_name/tokenized_feats/name.h5ad\n",
    "        # gexp.write_h5ad()\n",
    "\n",
    "        return gexp\n",
    "    \n",
    "    def __call__(self, gexp, context_length: Optional[int] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the tokenized representation of given input gexp(s) from GeneFormer paper\n",
    "        Parameters\n",
    "        ----------\n",
    "        gexp : Union[numpy/list, List[numpy/list]]\n",
    "            An input gexpr or a list of input gexpr to tokenize\n",
    "        context_length : int\n",
    "            The context length to use as input to GeneFormer; \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A two-dimensional tensor containing the resulting tokens, shape = [number of input gexp, context_length]\n",
    "        \"\"\"\n",
    "        gexp = self.tokenize_anndata(gexp)\n",
    "\n",
    "\n",
    "        return gexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anndata_processed_files_path = \"/home/ubuntu/SpatialCLIP/datasets/HumanPanVisium/Processed\"\n",
    "adata_sample_dict = {}\n",
    "for file in os.listdir(anndata_processed_files_path):\n",
    "    if file.endswith(\".h5ad\"):\n",
    "        adata_sample_dict[file.split(\".\")[0]] = sc.read_h5ad(os.path.join(anndata_processed_files_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['V10L13-019-A1', 'V11J26-002-B1', 'V19L29-095-A1', 'V19B23-014-A1', 'V52Y10-365-A1', 'V52Y09-003-B1', 'V52Y10-317-B1', 'V19L29-097-B1', 'V19L01-033-A1', 'V19S16-046-C1', 'V10A13-206-C1', 'V52Y10-310-A1', 'V10A13-167-C1', 'V52Y10-286-B1', 'V10L13-020-D1', 'V19L29-098-B1', 'V42A20-354-D1', 'V10L13-021-B1', 'V42U20-030-A1', 'V10M18-056-C1'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_sample_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3940034/3359423947.py:53: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  for i in gexp.var[\"ensembl_id\"][coding_miRNA_loc]\n",
      "/tmp/ipykernel_3940034/3359423947.py:56: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coding_miRNA_ids = gexp.var[\"ensembl_id\"][coding_miRNA_loc]\n"
     ]
    }
   ],
   "source": [
    "geneformer_tokenizer = GeneformerTokenizer(nproc=4)\n",
    "V11J26_adata = geneformer_tokenizer(adata_sample_dict['V11J26-002-B1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3940034/3359423947.py:53: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  for i in gexp.var[\"ensembl_id\"][coding_miRNA_loc]\n",
      "/tmp/ipykernel_3940034/3359423947.py:56: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coding_miRNA_ids = gexp.var[\"ensembl_id\"][coding_miRNA_loc]\n"
     ]
    }
   ],
   "source": [
    "# create an empty numpy array of name \"accum_V11J26_adata\"\n",
    "accum_V11J26_adata = []\n",
    "for i in range(adata_sample_dict['V11J26-002-B1'].shape[0]):\n",
    "    accum_V11J26_adata += geneformer_tokenizer(adata_sample_dict['V11J26-002-B1'][i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3940034/1378494248.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  V11J26_adata = np.array(V11J26_adata)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 3043)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V11J26_adata = np.array(V11J26_adata)\n",
    "V11J26_adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([  351, 12103, 20387, ...,  6850,  9623, 10950], dtype=int16),\n",
       "        array([  351, 12103,  2218, ...,  5433,  3098, 13393], dtype=int16),\n",
       "        array([12103, 16683,   351, ...,  6850, 13393, 12938], dtype=int16),\n",
       "        ...,\n",
       "        array([  351,  6556, 12103, ..., 13393,  6850,  8385], dtype=int16),\n",
       "        array([  351, 12103, 16683, ..., 14204, 15711,  8385], dtype=int16),\n",
       "        array([  351, 12103,   317, ..., 16224, 13393,  4384], dtype=int16)]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V11J26_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3043)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum_V11J26_adata = np.array(accum_V11J26_adata).T\n",
    "accum_V11J26_adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([  351, 12103, 20387, ...,  6850,  9623, 10950], dtype=int16),\n",
       "        array([  351, 12103,  2218, ...,  5433,  3098, 13393], dtype=int16),\n",
       "        array([12103, 16683,   351, ...,  6850, 13393, 12938], dtype=int16),\n",
       "        ...,\n",
       "        array([  351,  6556, 12103, ..., 13393,  6850,  8385], dtype=int16),\n",
       "        array([  351, 12103, 16683, ..., 14204, 15711,  8385], dtype=int16),\n",
       "        array([  351, 12103,   317, ..., 16224, 13393,  4384], dtype=int16)]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum_V11J26_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where is the difference between V11J26_adata[0][0] and accum_V11J26_adata[0][0]?\n",
    "q = V11J26_adata[0][0] == accum_V11J26_adata[0][0]\n",
    "# get index of False in q\n",
    "np.where(q == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5354,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3940034/779235624.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  V11J26_adata[0][0] == accum_V11J26_adata[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V11J26_adata[0][0] == accum_V11J26_adata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
